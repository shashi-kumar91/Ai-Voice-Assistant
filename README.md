# ğŸ§  AI Voice Assistant

A real-time voice-enabled assistant built with Python that listens to your speech, transcribes it using Whisper, processes it via LLaMA 3 (Groq API), and responds back in natural voice using TTS. Includes support for live interruption, making conversations more human-like.

---

## ğŸ¯ Features

- ğŸ™ï¸ **Speech-to-Text**: Converts user voice input to text using [Whisper](https://github.com/openai/whisper).
- ğŸ¤– **AI Responses**: Sends input to a Large Language Model (LLaMA 3 via Groq API) and returns a relevant reply.
- ğŸ”Š **Text-to-Speech**: Converts AI response back to speech using `gTTS` and `pygame`.
- â›” **Interruptible Output**: Stop speech mid-way and change the topic using an interrupt button.
- ğŸŒ **User Interface**: Clean web UI built using [Streamlit](https://streamlit.io/).

---

## ğŸ› ï¸ Tech Stack

- **Frontend/UI**: Streamlit
- **Speech-to-Text**: Whisper (via `faster-whisper`)
- **LLM Integration**: LLaMA 3 via Groq API
- **Text-to-Speech**: gTTS + pygame (fallback for reliability)
- **Audio Handling**: PyAudio, SoundDevice, threading
- **Language**: Python

---

## ğŸš€ Installation

```bash
# Clone the repo
git clone https://github.com/shashi-kumar91/AI-Voice-Assistant.git
cd AI-Voice-Assistant

# Create a virtual environment (optional but recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install requirements
pip install -r requirements.txt
